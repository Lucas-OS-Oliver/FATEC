{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "authorship_tag": "ABX9TyNTGfTVEiiCW1cjdWTzA5ra",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucasKoodah/FATEC/blob/master/YOLO_Lucas_Jonata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGpJL1wXa7kO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#INTEGRANTES:#\n",
        "#JONATA BERTOLONI DE VASCONCELOS  R.A.: 0791711024#\n",
        "#LUCAS OLIVEIRA DE SOUZA  R.A.: 0791721002#\n",
        "#IMPORTANDO IMAGEM(ENS) DO COMPUTADOR#\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "#IMPORTANDO BIBLIOTECAS#\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "#BANCO COM 30 IMAGENS DISPONIBILIZADAS PELO PROFESSOR MURILO#\n",
        "imagem = []\n",
        "imagem.append(\"austin-distel-744oGeqpxPQ-unsplash.jpg\")\n",
        "imagem.append(\"anastasia-zhenina-fPX0XHxzCxI-unsplash.jpg\")\n",
        "imagem.append(\"austin-distel-EMPZ7yRZoGw-unsplash.jpg\")\n",
        "imagem.append(\"austin-distel-Jn1csk3lWDA-unsplash.jpg\")\n",
        "imagem.append(\"austin-distel-jpHw8ndwJ_Q-unsplash.jpg\")\n",
        "imagem.append(\"bruno-cervera-4i_9a-d_Q3E-unsplash.jpg\")\n",
        "imagem.append(\"chelsea-gates-faPPevPD0MQ-unsplash.jpg\")\n",
        "imagem.append(\"eggbank-ueAYDXll_N8-unsplash.jpg\")\n",
        "imagem.append(\"elle-hughes-ajTlDUwLuJk-unsplash.jpg\")\n",
        "imagem.append(\"erik-mclean-g6YNrpOq1Gk-unsplash.jpg\")\n",
        "imagem.append(\"eugene-zhyvchik-KUqJuDtrVkw-unsplash.jpg\")\n",
        "imagem.append(\"eugene-zhyvchik-u1gE6lvbloc-unsplash.jpg\")\n",
        "imagem.append(\"hiep-duong-cqspyPWxW_M-unsplash.jpg\")\n",
        "imagem.append(\"ilyuza-mingazova-2qMldY33AMo-unsplash.jpg\")\n",
        "imagem.append(\"isaac-quesada-1mvrY8osYkM-unsplash.jpg\")\n",
        "imagem.append(\"joshua-koblin-4hUxLunmxPM-unsplash.jpg\")\n",
        "imagem.append(\"lance-anderson-ixBBY-WuFRU-unsplash.jpg\")\n",
        "imagem.append(\"li-lin-0-MHQAG9XoA-unsplash.jpg\")\n",
        "imagem.append(\"marianna-berno-QK_ufggzGCk-unsplash.jpg\")\n",
        "imagem.append(\"nathan-anderson-0wKpv3o8D1I-unsplash.jpg\")\n",
        "imagem.append(\"neonbrand-AOJGuIJkoBc-unsplash.jpg\")\n",
        "imagem.append(\"neonbrand-JW6r_0CPYec-unsplash.jpg\")\n",
        "imagem.append(\"romain-b-Y0Mxn4xG4hA-unsplash.jpg\")\n",
        "imagem.append(\"surface-C389V--ZZrQ-unsplash.jpg\")\n",
        "imagem.append(\"surface-DQfIfnTuT3w-unsplash.jpg\")\n",
        "imagem.append(\"surface-O9m5k3_-iAs-unsplash.jpg\")\n",
        "imagem.append(\"thomas-de-luze-7xDfU-htISs-unsplash.jpg\")\n",
        "imagem.append(\"tim-motivv-AJCil71FOrc-unsplash.jpg\")\n",
        "imagem.append(\"tyler-nix-KFVsFjTTkBo-unsplash.jpg\")\n",
        "imagem.append(\"waldemar-brandt-FjAwyE8DLPw-unsplash.jpg\")\n",
        "escolha = int(input(\"Qual imagem deseja trabalhar? Escolha entre 0 e 29? \"))\n",
        "foto = cv2.imread(imagem[escolha])\n",
        "cv2_imshow(foto)\n",
        "largura = foto.shape[1]\n",
        "altura = foto.shape[0]\n",
        "escala = 0.00392\n",
        "#LER OS NOMES DE CLASSE DO ARQUIVO DO TEXTO#\n",
        "classes = None\n",
        "with open('yolov3.txt', 'r') as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "#GERAR DIFERENTES CORES PARA DIFERENTES CLASSES#\n",
        "COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        "#LER O MODELO PRÉ-TREINADO E OS ARQUIVOS DE CONFIGURAÇÃO (WEIGHTS E CFG)#\n",
        "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')\n",
        "#CRIAR BLOB DE ENTRADA#\n",
        "blob = cv2.dnn.blobFromImage(foto, escala, (416,416), (0,0,0), True, crop=False)\n",
        "#SETAR BLOB DE ENTRADA PARA A REDE#\n",
        "net.setInput(blob)\n",
        "#OBTER NOMES DAS CAMADAS DE SAÍDA#\n",
        "def get_output_layers(net):\n",
        "    \n",
        "    layer_names = net.getLayerNames()\n",
        "    \n",
        "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "    return output_layers\n",
        "#DESENHAR CAIXAS EM VOLTA DO OBJETO/PESSOAS DETECTADAS#\n",
        "def draw_bounding_box(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
        "    label = str(classes[class_id])\n",
        "    color = COLORS[class_id]\n",
        "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 20)\n",
        "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 5, color, 20)\n",
        "#EXECUTAR ATRAVÉS DA REDE#\n",
        "outs = net.forward(get_output_layers(net))\n",
        "#RODANDO\n",
        "class_ids = []\n",
        "confidences = []\n",
        "boxes = []\n",
        "conf_threshold = 0.5\n",
        "nms_threshold = 0.4\n",
        "#PARA CADA OBJETO/PESSOAS DETECTADAS DEVE CLASSIFICAR, CASO RECONHEÇA ACIMA DE 50%#\n",
        "for out in outs:\n",
        "    for detection in out:\n",
        "        scores = detection[5:]\n",
        "        class_id = np.argmax(scores)\n",
        "        confidence = scores[class_id]\n",
        "        if confidence > 0.5:\n",
        "            center_x = int(detection[0] * largura)\n",
        "            center_y = int(detection[1] * altura)\n",
        "            w = int(detection[2] * largura)\n",
        "            h = int(detection[3] * altura)\n",
        "            x = center_x - w / 2\n",
        "            y = center_y - h / 2\n",
        "            class_ids.append(class_id)\n",
        "            confidences.append(float(confidence))\n",
        "            boxes.append([x, y, w, h])\n",
        "indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
        "#PASSAR POR TODAS AS OUTRAS DETECÇÕES E DESENHAR A CAIXA EM TORNO DO ALVO#\n",
        "for i in indices:\n",
        "    i = i[0]\n",
        "    box = boxes[i]\n",
        "    x = box[0]\n",
        "    y = box[1]\n",
        "    w = box[2]\n",
        "    h = box[3]\n",
        "    \n",
        "    draw_bounding_box(foto, class_ids[i], confidences[i], round(x), round(y), round(x+w), round(y+h))\n",
        "#MOSTRAR IMAGEM COM DETECÇÃO#  \n",
        "cv2_imshow(foto)\n",
        "#LIBERA OS RECURSOS#\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}